{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxfkGXHiSQTZIlemZA80ka"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNMf-0cxX9ay","executionInfo":{"status":"ok","timestamp":1705091548089,"user_tz":-60,"elapsed":36629,"user":{"displayName":"Jelena Lazic","userId":"09413113576588392797"}},"outputId":"b9cdb057-7a96-4014-f51d-6de6c47641a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import nltk\n","from nltk import sent_tokenize  # Make sure to install nltk if not already installed: !pip install nltk"],"metadata":{"id":"jn6Ks4EcY9rs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ri1eiRQZZl_","executionInfo":{"status":"ok","timestamp":1704910099519,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jelena Lazic","userId":"09413113576588392797"}},"outputId":"243ae9bb-6726-44db-a622-a9f1f7677c32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["def read_first_sentence(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        content = file.read()\n","\n","        # Split the content based on '\\nWord:'\n","        parts = content.split('\\nWord:')\n","        if len(parts) > 0:\n","            transcript_text = parts[0].strip()\n","        else:\n","            transcript_text = content.strip()\n","\n","        # Remove \"Transcript:\" from the beginning of each sentence\n","        transcript_text = transcript_text.replace('Transcript:', '')\n","\n","        sentences = sent_tokenize(transcript_text)\n","        if sentences:\n","            return sentences[0]\n","        else:\n","            return None"],"metadata":{"id":"CJN5tt7_Y__1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","root_folder = '/content/drive/MyDrive/PhD/Forced_alignment/transcript'  # Replace with the path to your root folder\n","\n","data = {'File': [], 'First Sentence': []}\n","\n","for root, dirs, files in os.walk(root_folder):\n","    for file in files:\n","        if file.lower().endswith(\".txt\"):\n","            file_path = os.path.join(root, file)\n","            first_sentence = read_first_sentence(file_path)\n","\n","                # If the file contains at least one sentence\n","            if first_sentence is not None:\n","                data['File'].append(file_path)\n","                data['First Sentence'].append(first_sentence)\n","\n","df = pd.DataFrame(data)"],"metadata":{"id":"qrd_W4-sZCtE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the DataFrame to a CSV file\n","df.to_csv(\"/content/drive/MyDrive/PhD/Transcript - correct/first_sentences.csv\", index=False)"],"metadata":{"id":"LzrSeLnKZDzO"},"execution_count":null,"outputs":[]}]}